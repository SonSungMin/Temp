!pip install -q pandas_ta requests beautifulsoup4 tabulate

import pandas as pd
import pandas_ta as ta
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import pytz
from tabulate import tabulate
import warnings
import time
import re

warnings.filterwarnings("ignore")

def get_sector_leaders():
    """ì„¹í„°ë³„(í…Œë§ˆë³„) ìƒìŠ¹ ìš°ëŸ‰ì£¼ ìˆ˜ì§‘"""
    headers = {'User-Agent': 'Mozilla/5.0'}
    ticker_map = {}
    
    start_time = time.time()
    
    # 1. ì‹œê°€ì´ì•¡ ìƒìœ„
    print("ğŸ“Š [1/4] ì‹œê°€ì´ì•¡ ìƒìœ„ ìš°ëŸ‰ì£¼ ìˆ˜ì§‘ ì¤‘...", end=' ', flush=True)
    step_start = time.time()
    urls_cap = [
        "https://finance.naver.com/sise/sise_market_sum.naver?sosok=0&page=1",
        "https://finance.naver.com/sise/sise_market_sum.naver?sosok=0&page=2",
        "https://finance.naver.com/sise/sise_market_sum.naver?sosok=1&page=1",
    ]
    
    for url in urls_cap:
        try:
            res = requests.get(url, headers=headers, timeout=5)
            soup = BeautifulSoup(res.text, 'html.parser')
            links = soup.select('a.tltle')
            for link in links:
                name, code = link.text, link['href'].split('=')[-1]
                ticker_map[code] = {'name': name, 'source': 'ì‹œì´ìƒìœ„'}
        except:
            continue
    print(f"ì™„ë£Œ ({time.time() - step_start:.1f}ì´ˆ, {len(ticker_map)}ê°œ)")
    
    # 2. ìƒìŠ¹ë¥  ìƒìœ„
    print("ğŸ“ˆ [2/4] ìƒìŠ¹ë¥  ìƒìœ„ ì¢…ëª© ìˆ˜ì§‘ ì¤‘...", end=' ', flush=True)
    step_start = time.time()
    urls_rise = [
        "https://finance.naver.com/sise/sise_rise.naver?sosok=0",
        "https://finance.naver.com/sise/sise_rise.naver?sosok=1",
    ]
    
    count_before = len(ticker_map)
    for url in urls_rise:
        try:
            res = requests.get(url, headers=headers, timeout=5)
            soup = BeautifulSoup(res.text, 'html.parser')
            links = soup.select('a.tltle')
            for link in links[:30]:
                name, code = link.text, link['href'].split('=')[-1]
                if code not in ticker_map:
                    ticker_map[code] = {'name': name, 'source': 'ìƒìŠ¹ë¥ ìƒìœ„'}
        except:
            continue
    print(f"ì™„ë£Œ ({time.time() - step_start:.1f}ì´ˆ, +{len(ticker_map) - count_before}ê°œ)")
    
    # 3. ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„
    print("ğŸ’° [3/4] ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ ì¢…ëª© ìˆ˜ì§‘ ì¤‘...", end=' ', flush=True)
    step_start = time.time()
    urls_amount = [
        "https://finance.naver.com/sise/sise_deal_amount.naver?sosok=0",
        "https://finance.naver.com/sise/sise_deal_amount.naver?sosok=1",
    ]
    
    count_before = len(ticker_map)
    for url in urls_amount:
        try:
            res = requests.get(url, headers=headers, timeout=5)
            soup = BeautifulSoup(res.text, 'html.parser')
            links = soup.select('a.tltle')
            for link in links[:30]:
                name, code = link.text, link['href'].split('=')[-1]
                if code not in ticker_map:
                    ticker_map[code] = {'name': name, 'source': 'ê±°ë˜ëŒ€ê¸ˆìƒìœ„'}
        except:
            continue
    print(f"ì™„ë£Œ ({time.time() - step_start:.1f}ì´ˆ, +{len(ticker_map) - count_before}ê°œ)")
    
    print(f"\nâœ… ì¢…ëª© ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(ticker_map)}ê°œ (ì†Œìš” ì‹œê°„: {time.time() - start_time:.1f}ì´ˆ)\n")
    
    return ticker_map

def get_naver_stock_data(code):
    """ë„¤ì´ë²„ì—ì„œ ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì¼ë´‰)"""
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    try:
        # ì¼ë´‰ ë°ì´í„° (ìµœê·¼ 60ì¼)
        url = f"https://fchart.stock.naver.com/sise.nhn?symbol={code}&timeframe=day&count=60&requestType=0"
        res = requests.get(url, headers=headers, timeout=5)
        
        if res.status_code != 200:
            return None
        
        # XML íŒŒì‹±
        soup = BeautifulSoup(res.text, 'xml')
        items = soup.find_all('item')
        
        if not items:
            return None
        
        data = []
        for item in items:
            try:
                date_str = item['data'].split('|')[0]
                open_price = int(item['data'].split('|')[1])
                high_price = int(item['data'].split('|')[2])
                low_price = int(item['data'].split('|')[3])
                close_price = int(item['data'].split('|')[4])
                volume = int(item['data'].split('|')[5])
                
                data.append({
                    'Date': pd.to_datetime(date_str),
                    'Open': open_price,
                    'High': high_price,
                    'Low': low_price,
                    'Close': close_price,
                    'Volume': volume
                })
            except:
                continue
        
        if not data:
            return None
        
        df = pd.DataFrame(data)
        df.set_index('Date', inplace=True)
        df.sort_index(inplace=True)
        
        return df
        
    except Exception as e:
        return None

def get_naver_current_price(code):
    """ë„¤ì´ë²„ì—ì„œ í˜„ì¬ê°€ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì‹œê°€ì´ì•¡ í¬í•¨)"""
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    try:
        url = f"https://finance.naver.com/item/main.naver?code={code}"
        res = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ì‹œê°€ì´ì•¡ (ì–µì›)
        market_cap = 0
        market_cap_elem = soup.select_one('em#_market_sum')
        if market_cap_elem:
            cap_text = market_cap_elem.text.strip().replace(',', '')
            try:
                market_cap = int(cap_text)
            except:
                market_cap = 0
        
        return market_cap
        
    except:
        return 0

def check_market_status(now_kst):
    """ì¥ ìš´ì˜ ì‹œê°„ í™•ì¸"""
    weekday = now_kst.weekday()
    hour = now_kst.hour
    minute = now_kst.minute
    
    if weekday >= 5:
        return "ì£¼ë§ (ì¥ ë§ˆê°)", False
    
    if hour < 9:
        return "ì¥ ì‹œì‘ ì „", False
    elif hour == 9 and minute < 0:
        return "ì¥ ì‹œì‘ ì „", False
    elif hour > 15 or (hour == 15 and minute > 30):
        return "ì¥ ë§ˆê° í›„", False
    else:
        return "ì¥ ìš´ì˜ ì¤‘", True

def check_support_resistance(df, current_price):
    """ì§€ì§€/ì €í•­ ëŒíŒŒ í™•ì¸"""
    highs = df['High'].tail(20)
    lows = df['Low'].tail(20)
    resistance = highs.max()
    support = lows.min()
    breakout = current_price > resistance * 0.99
    near_support = current_price < support * 1.02
    return breakout, near_support, resistance, support

def check_volume_pattern(df):
    """ê±°ë˜ëŸ‰ íŒ¨í„´ ë¶„ì„"""
    vols = df['Volume'].tail(5)
    vol_ma = df['Volume'].tail(20).mean()
    volume_surge = all(vols.iloc[i] < vols.iloc[i+1] for i in range(len(vols)-1))
    volume_explosion = vols.iloc[-1] > vol_ma * 2.0
    return volume_surge, volume_explosion

def check_price_action(df):
    """ê°€ê²© í–‰ë™ íŒ¨í„´"""
    recent = df.tail(5)
    consecutive_green = all(recent['Close'].iloc[i] > recent['Open'].iloc[i] for i in range(len(recent)))
    
    pullback_rally = False
    if len(recent) >= 4:
        uptrend = recent['Close'].iloc[-4] < recent['Close'].iloc[-3] < recent['Close'].iloc[-2]
        pullback = recent['Close'].iloc[-2] > recent['Close'].iloc[-1]
        rally = recent['Close'].iloc[-1] > recent['Open'].iloc[-1]
        pullback_rally = uptrend and pullback and rally
    
    last = df.iloc[-1]
    body = abs(last['Close'] - last['Open'])
    total_range = last['High'] - last['Low']
    lower_shadow = min(last['Open'], last['Close']) - last['Low']
    hammer = (lower_shadow > body * 2) and (total_range > 0) and (last['Close'] > last['Open'])
    
    return consecutive_green, pullback_rally, hammer

def calculate_bollinger_bands(df):
    """ë³¼ë¦°ì € ë°´ë“œ"""
    try:
        bb = ta.bbands(df['Close'], length=20, std=2)
        if bb is None or bb.empty:
            return False, False
        
        current_price = df['Close'].iloc[-1]
        lower_band = bb['BBL_20_2.0'].iloc[-1]
        upper_band = bb['BBU_20_2.0'].iloc[-1]
        middle_band = bb['BBM_20_2.0'].iloc[-1]
        
        touch_lower = current_price < lower_band * 1.01
        cross_middle = current_price > middle_band and df['Close'].iloc[-2] < middle_band
        near_upper = current_price > upper_band * 0.98
        
        return (touch_lower or cross_middle), near_upper
    except:
        return False, False

def check_macd_signal(df):
    """MACD ì‹ í˜¸"""
    try:
        macd = ta.macd(df['Close'])
        if macd is None or macd.empty:
            return False, False
        
        macd_line = macd['MACD_12_26_9']
        signal_line = macd['MACDs_12_26_9']
        
        golden_cross = (macd_line.iloc[-1] > signal_line.iloc[-1]) and (macd_line.iloc[-2] <= signal_line.iloc[-2])
        death_cross = (macd_line.iloc[-1] < signal_line.iloc[-1]) and (macd_line.iloc[-2] >= signal_line.iloc[-2])
        
        return golden_cross, death_cross
    except:
        return False, False

def run_sector_scanner():
    kst = pytz.timezone('Asia/Seoul')
    now_kst = datetime.now(kst)
    
    market_status, is_trading = check_market_status(now_kst)
    
    print(f"{'='*120}")
    print(f"ğŸ¯ ì„¹í„°ë³„ ìš°ëŸ‰ ìƒìŠ¹ì£¼ ìŠ¤ìºë„ˆ (ë„¤ì´ë²„ ê¸ˆìœµ ë°ì´í„°)")
    print(f"ğŸ“… ë¶„ì„ ì‹¤í–‰ ì‹œê°: {now_kst.strftime('%Y-%m-%d %H:%M:%S')} ({now_kst.strftime('%A')})")
    print(f"ğŸ¢ ì‹œì¥ ìƒíƒœ: {market_status}")
    print(f"{'='*120}\n")
    
    overall_start = time.time()
    
    ticker_map = get_sector_leaders()
    
    print(f"{'='*120}")
    print(f"ğŸ“¡ ì¢…ëª© ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„ ì‹œì‘ (ì´ {len(ticker_map)}ê°œ)")
    print(f"{'='*120}\n")
    
    # í†µê³„
    stats = {
        'total': 0,
        'small_cap': 0,
        'data_fail': 0,
        'data_fail_reasons': {},
        'no_change': 0,
        'decline': 0,
        'upper_limit': 0,
        'low_volume': 0,
        'rsi_over': 0,
        'score_fail': 0,
        'passed': 0
    }
    
    results = []
    detailed_logs = []
    
    # ë°ì´í„° ì‹œê°„ ì¶”ì 
    latest_data_time = None
    
    # ì„±ëŠ¥ ì¸¡ì •
    download_times = []
    analysis_times = []
    total_tickers = len(ticker_map)
    current_idx = 0
    
    for code, info in ticker_map.items():
        current_idx += 1
        stats['total'] += 1
        stock_name = info['name']
        source = info['source']
        
        # ì§„í–‰ë¥  í‘œì‹œ
        if current_idx % 20 == 0 or current_idx == 1:
            print(f"ì§„í–‰: {current_idx}/{total_tickers} ({current_idx/total_tickers*100:.1f}%) - í˜„ì¬: {stock_name}", flush=True)
        
        try:
            # === ì‹œê°€ì´ì•¡ í™•ì¸ ===
            market_cap = get_naver_current_price(code)
            if 0 < market_cap < 100:
                stats['small_cap'] += 1
                detailed_logs.append(f"âŒ {stock_name} ({source}): ì´ˆì†Œí˜•ì£¼ ì œì™¸ (ì‹œì´ {market_cap:.0f}ì–µ)")
                continue
            
            # === ë°ì´í„° ë‹¤ìš´ë¡œë“œ ===
            download_start = time.time()
            
            df = get_naver_stock_data(code)
            
            download_time = time.time() - download_start
            download_times.append(download_time)
            
            if df is None or df.empty:
                stats['data_fail'] += 1
                reason = "ë°ì´í„° ì—†ìŒ"
                stats['data_fail_reasons'][reason] = stats['data_fail_reasons'].get(reason, 0) + 1
                detailed_logs.append(f"âŒ {stock_name} ({source}): {reason}")
                continue
                
            if len(df) < 20:
                stats['data_fail'] += 1
                reason = f"ë°ì´í„° ë¶€ì¡± ({len(df)}ê°œ < 20ê°œ)"
                stats['data_fail_reasons'][reason] = stats['data_fail_reasons'].get(reason, 0) + 1
                detailed_logs.append(f"âŒ {stock_name} ({source}): {reason}")
                continue
            
            # ë°ì´í„° ìµœì‹  ì‹œê°„
            data_latest_time = df.index[-1]
            data_latest_kst = data_latest_time.tz_localize(kst) if data_latest_time.tzinfo is None else data_latest_time.astimezone(kst)
            
            if latest_data_time is None or data_latest_kst > latest_data_time:
                latest_data_time = data_latest_kst
            
            # ë°ì´í„° ì‹ ì„ ë„
            data_age_hours = (now_kst - data_latest_kst).total_seconds() / 3600
            if data_age_hours > 48:
                stats['data_fail'] += 1
                reason = "ë°ì´í„° ì˜¤ë˜ë¨"
                stats['data_fail_reasons'][reason] = stats['data_fail_reasons'].get(reason, 0) + 1
                detailed_logs.append(f"â° {stock_name} ({source}): {reason} (ìµœì‹ : {data_latest_kst.strftime('%m-%d')}, {data_age_hours/24:.1f}ì¼ ì „)")
                continue
            
            # === ê¸°ìˆ ì  ë¶„ì„ ì‹œì‘ ===
            analysis_start = time.time()
            
            # ê¸°ë³¸ ì§€í‘œ
            df['ma5'] = ta.sma(df['Close'], length=5)
            df['ma20'] = ta.sma(df['Close'], length=20)
            df['ma60'] = ta.sma(df['Close'], length=60)
            df['rsi'] = ta.rsi(df['Close'], length=14)
            df['vol_ma20'] = ta.sma(df['Volume'], length=20)

            curr = df.iloc[-1]
            prev = df.iloc[-2]
            
            c_close = float(curr['Close'])
            p_close = float(prev['Close'])
            c_vol = float(curr['Volume'])
            vol_ma20 = float(curr['vol_ma20']) if not pd.isna(curr['vol_ma20']) else 1
            c_ma5 = float(curr['ma5']) if not pd.isna(curr['ma5']) else c_close
            c_ma20 = float(curr['ma20']) if not pd.isna(curr['ma20']) else c_close
            c_ma60 = float(curr['ma60']) if not pd.isna(curr['ma60']) else c_close
            c_rsi = float(curr['rsi']) if not pd.isna(curr['rsi']) else 50
            
            surge_rate = ((c_close - p_close) / p_close) * 100
            vol_ratio = c_vol / vol_ma20 if vol_ma20 > 0 else 0
            
            # === í•„í„°ë§ ===
            
            # 1. ë³´í•©/í•˜ë½ ì œì™¸
            if abs(surge_rate) < 0.5:
                stats['no_change'] += 1
                detailed_logs.append(f"âšª {stock_name} ({source}): ë³´í•© (ë“±ë½ {surge_rate:.1f}%)")
                continue
            
            if surge_rate < -2.0:
                stats['decline'] += 1
                detailed_logs.append(f"ğŸ”» {stock_name} ({source}): í•˜ë½ ì¤‘ ({surge_rate:.1f}%)")
                continue
            
            # 2. ìƒí•œê°€ ì œì™¸
            if surge_rate >= 28.0:
                stats['upper_limit'] += 1
                detailed_logs.append(f"ğŸš« {stock_name} ({source}): ìƒí•œê°€ ê·¼ì ‘ ({surge_rate:.1f}%)")
                continue
            
            # 3. ê±°ë˜ëŸ‰
            if vol_ratio < 1.0:
                stats['low_volume'] += 1
                detailed_logs.append(f"ğŸ“‰ {stock_name} ({source}): ê±°ë˜ëŸ‰ ë¶€ì¡± ({vol_ratio:.1f}ë°°)")
                continue
            
            # 4. RSI ê³¼ì—´
            if c_rsi > 85:
                stats['rsi_over'] += 1
                detailed_logs.append(f"ğŸ”¥ {stock_name} ({source}): RSI ê³¼ì—´ ({c_rsi:.1f})")
                continue
            
            # === ì ìˆ˜ ì‚°ì • ===
            score = 0
            signals = []
            risk_flags = []
            
            # ìš°ëŸ‰ì£¼ ë³´ë„ˆìŠ¤
            if market_cap > 10000:
                score += 15
                signals.append(f"ëŒ€í˜•ì£¼{int(market_cap/10000)}ì¡°")
            elif market_cap > 5000:
                score += 12
                signals.append(f"ì¤‘ëŒ€í˜•{int(market_cap/1000)}ì²œì–µ")
            elif market_cap > 1000:
                score += 8
                signals.append(f"ì¤‘í˜•{int(market_cap/1000)}ì²œì–µ")
            elif market_cap > 500:
                score += 5
                signals.append(f"ì¤‘ì†Œí˜•{int(market_cap)}ì–µ")
            elif market_cap > 200:
                score += 3
                signals.append(f"ì†Œí˜•{int(market_cap)}ì–µ")
            else:
                signals.append(f"ì´ˆì†Œí˜•{int(market_cap)}ì–µ")
            
            # ì§€ì§€/ì €í•­
            breakout, near_support, resistance, support = check_support_resistance(df, c_close)
            if breakout:
                score += 20
                signals.append("ê³ ì ëŒíŒŒ")
            
            # ê±°ë˜ëŸ‰ íŒ¨í„´
            vol_surge, vol_explosion = check_volume_pattern(df)
            if vol_explosion:
                score += 20
                signals.append("ê±°ë˜í­ë°œ")
            elif vol_surge:
                score += 10
                signals.append("ê±°ë˜ì¦ê°€")
            
            # ê°€ê²© í–‰ë™
            consecutive_green, pullback_rally, hammer = check_price_action(df)
            if consecutive_green:
                score += 12
                signals.append("ì—°ì†ìƒìŠ¹")
            if pullback_rally:
                score += 18
                signals.append("ì¡°ì •í›„ë°˜ë“±")
            if hammer:
                score += 12
                signals.append("ë°˜ì „ìº”ë“¤")
            
            # ë³¼ë¦°ì € ë°´ë“œ
            bb_buy_signal, bb_overbought = calculate_bollinger_bands(df)
            if bb_buy_signal:
                score += 12
                signals.append("BBë§¤ìˆ˜")
            if bb_overbought:
                score -= 10
                risk_flags.append("ê³¼ì—´")
            
            # MACD
            macd_golden, macd_death = check_macd_signal(df)
            if macd_golden:
                score += 18
                signals.append("MACDê³¨ë“ ")
            if macd_death:
                score -= 15
                risk_flags.append("MACDë§¤ë„")
            
            # ì´ë™í‰ê· ì„ 
            if c_ma5 > c_ma20 > c_ma60:
                score += 12
                signals.append("ì •ë°°ì—´")
            elif c_ma5 < c_ma20:
                score -= 8
                risk_flags.append("ì—­ë°°ì—´")
            
            # RSI
            if 50 <= c_rsi <= 75:
                score += 10
                signals.append("RSIì–‘í˜¸")
            elif 30 <= c_rsi < 50:
                score += 8
                signals.append("RSIíšŒë³µ")
            
            # ê¸‰ë“±ë¥ 
            if 10 <= surge_rate < 28:
                score += 15
                signals.append(f"ê°•ìƒìŠ¹{surge_rate:.1f}%")
            elif 5 <= surge_rate < 10:
                score += 12
                signals.append(f"ìƒìŠ¹{surge_rate:.1f}%")
            elif 2 <= surge_rate < 5:
                score += 8
                signals.append(f"ì™„ë§Œ{surge_rate:.1f}%")
            elif -2 <= surge_rate < 2:
                score += 3
                signals.append(f"ë³´í•©{surge_rate:.1f}%")
            
            # ìµœì†Œ ì ìˆ˜
            if market_cap > 5000:
                min_score = 40
            elif market_cap > 1000:
                min_score = 45
            elif market_cap > 500:
                min_score = 50
            else:
                min_score = 55
                
            if score < min_score:
                stats['score_fail'] += 1
                detailed_logs.append(f"âš ï¸  {stock_name} ({source}): ì‹ ë¢°ë„ ë¶€ì¡± ({score}ì  < {min_score}ì , ì‹œì´ {int(market_cap)}ì–µ)")
                continue
            
            # í†µê³¼!
            stats['passed'] += 1
            risk_level = "ë†’ìŒ" if len(risk_flags) >= 2 else "ì¤‘ê°„" if len(risk_flags) == 1 else "ë‚®ìŒ"
            
            cap_display = f"{int(market_cap/10000)}ì¡°" if market_cap > 10000 else f"{int(market_cap/1000)}ì²œì–µ" if market_cap > 1000 else f"{int(market_cap)}ì–µ"
            
            data_time_display = data_latest_kst.strftime('%m/%d')
            
            detailed_logs.append(f"âœ… {stock_name} ({source}): í†µê³¼! ì‹œì´ {cap_display} | ì ìˆ˜ {score}ì  | ë°ì´í„°: {data_time_display}")
            
            results.append([
                stock_name,
                source,
                cap_display,
                f"{score}ì ", 
                risk_level,
                f"{int(c_close):,}ì›",
                f"{surge_rate:+.1f}%",
                f"{vol_ratio:.1f}ë°°", 
                f"{int(c_close*1.015):,}ì›",
                f"{int(c_close*0.985):,}ì›",
                " | ".join(signals[:3]) if signals else "-"
            ])
            
            # ë¶„ì„ ì‹œê°„ ê¸°ë¡
            analysis_time = time.time() - analysis_start
            analysis_times.append(analysis_time)
            
        except Exception as e:
            stats['data_fail'] += 1
            error_msg = str(e)[:80]
            reason = f"ì˜ˆì™¸ë°œìƒ: {error_msg}"
            stats['data_fail_reasons'][reason] = stats['data_fail_reasons'].get(reason, 0) + 1
            detailed_logs.append(f"âŒ {stock_name} ({source}): {reason}")
            continue
    
    total_time = time.time() - overall_start
    
    # === ì„±ëŠ¥ í†µê³„ ===
    print(f"\n{'='*120}")
    print(f"â±ï¸  ì„±ëŠ¥ ë¶„ì„")
    print(f"{'='*120}")
    print(f"ì „ì²´ ì†Œìš” ì‹œê°„: {total_time:.1f}ì´ˆ ({total_time/60:.1f}ë¶„)")
    
    if download_times:
        avg_download = sum(download_times) / len(download_times)
        total_download = sum(download_times)
        print(f"\nğŸ“¡ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ë„¤ì´ë²„ ê¸ˆìœµ):")
        print(f"  - ì´ ë‹¤ìš´ë¡œë“œ ì‹œê°„: {total_download:.1f}ì´ˆ ({total_download/total_time*100:.1f}%)")
        print(f"  - í‰ê·  ë‹¤ìš´ë¡œë“œ ì‹œê°„: {avg_download:.3f}ì´ˆ/ì¢…ëª©")
        print(f"  - ìµœëŒ€ ë‹¤ìš´ë¡œë“œ ì‹œê°„: {max(download_times):.2f}ì´ˆ")
        print(f"  - ë‹¤ìš´ë¡œë“œ íšŸìˆ˜: {len(download_times)}íšŒ")
        
    if analysis_times:
        avg_analysis = sum(analysis_times) / len(analysis_times)
        total_analysis = sum(analysis_times)
        print(f"\nğŸ“ˆ ê¸°ìˆ ì  ë¶„ì„:")
        print(f"  - ì´ ë¶„ì„ ì‹œê°„: {total_analysis:.1f}ì´ˆ ({total_analysis/total_time*100:.1f}%)")
        print(f"  - í‰ê·  ë¶„ì„ ì‹œê°„: {avg_analysis:.3f}ì´ˆ/ì¢…ëª©")
        print(f"  - ë¶„ì„ ì¢…ëª© ìˆ˜: {len(analysis_times)}ê°œ")
    
    print(f"\nğŸ’¡ ì¢…ëª©ë‹¹ í‰ê·  ì²˜ë¦¬: {total_time/total_tickers:.2f}ì´ˆ")
    print(f"ğŸ’¡ Yahoo Finance ëŒ€ë¹„ ì˜ˆìƒ ì†ë„ í–¥ìƒ: 5~10ë°°")
    
    # === ê²°ê³¼ ì¶œë ¥ ===
    print(f"\n{'='*120}")
    print(f"ğŸ“Š ë°ì´í„° ì •ë³´")
    print(f"{'='*120}")
    print(f"ğŸ“¡ ë°ì´í„° ì¶œì²˜: ë„¤ì´ë²„ ê¸ˆìœµ (í•œêµ­ ì„œë²„)")
    if latest_data_time:
        print(f"ğŸ“… ë°ì´í„° ìµœì‹  ì‹œê°: {latest_data_time.strftime('%Y-%m-%d')} (ì¼ë´‰)")
        data_delay = (now_kst - latest_data_time).total_seconds() / 3600
        if data_delay < 24:
            print(f"â±ï¸  ë°ì´í„° ì§€ì—°: {data_delay:.1f}ì‹œê°„ (ì‹ ì„ )")
        else:
            print(f"â±ï¸  ë°ì´í„° ì§€ì—°: {data_delay/24:.1f}ì¼")
    
    print(f"\n{'='*120}")
    print(f"ğŸ“Š í•„í„°ë§ í†µê³„")
    print(f"{'='*120}")
    print(f"ì´ ë¶„ì„: {stats['total']}ê°œ")
    print(f"  â”œâ”€ ì†Œí˜•ì£¼ ì œì™¸: {stats['small_cap']}ê°œ")
    print(f"  â”œâ”€ ë°ì´í„° ì˜¤ë¥˜: {stats['data_fail']}ê°œ")
    
    if stats['data_fail_reasons']:
        print(f"  â”‚   â””â”€ ì˜¤ë¥˜ ìƒì„¸:")
        for reason, count in sorted(stats['data_fail_reasons'].items(), key=lambda x: x[1], reverse=True):
            print(f"  â”‚       â”œâ”€ {reason}: {count}ê°œ")
    
    print(f"  â”œâ”€ ë³´í•©: {stats['no_change']}ê°œ")
    print(f"  â”œâ”€ í•˜ë½: {stats['decline']}ê°œ")
    print(f"  â”œâ”€ ìƒí•œê°€: {stats['upper_limit']}ê°œ")
    print(f"  â”œâ”€ ê±°ë˜ëŸ‰ ë¶€ì¡±: {stats['low_volume']}ê°œ")
    print(f"  â”œâ”€ RSI ê³¼ì—´: {stats['rsi_over']}ê°œ")
    print(f"  â”œâ”€ ì‹ ë¢°ë„ ë¶€ì¡±: {stats['score_fail']}ê°œ")
    print(f"  â””â”€ âœ… ìµœì¢… í†µê³¼: {stats['passed']}ê°œ")
    
    print(f"\n{'='*120}")
    print(f"ğŸ“‹ ìƒì„¸ ë¡œê·¸ (ìµœê·¼ 50ê°œ)")
    print(f"{'='*
